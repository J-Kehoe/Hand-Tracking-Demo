<!DOCTYPE html>
<html lang="en">
	<head>
		<title>Hand Tracking Demo</title>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
		<link rel="stylesheet" href="css/main.css"> 
	</head>
	<body>

        <video id="video" style="display:none" autoplay playsinline></video>
        <script src="https://threejs.org/build/three.js"></script>
        <!-- Be sure to use tfjs 1.7.4, in tfjs 2 they broke their own handpose model-->
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@1.7.4/dist/tf-core.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@1.7.4/dist/tf-converter.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose@0.0.4/dist/handpose.min.js"></script>

		<script type="module">

			import { OrbitControls } from '../js/OrbitControls.js'

            let camera, cameraPosition, scene, renderer, video;
            
            var handposeModel = null; // this will be loaded with the handpose model

            var videoDataLoaded = false; // is webcam capture ready?

            var statusText = "Loading handpose model...";

            var myHands = []; // hands detected
                            // currently handpose only supports single hand, so this will be either empty or singleton

            var handMeshes = []; // array of threejs objects that makes up the hand rendering

            var dbg = document.createElement("canvas").getContext('2d');
            dbg.canvas.style.position="absolute";
            dbg.canvas.style.left = "0px";
            dbg.canvas.style.top = "0px";
            dbg.canvas.style.zIndex = 100; // "bring to front"
            document.body.appendChild(dbg.canvas);

			init();
			animate();

			function init() {

                camera = new THREE.PerspectiveCamera(60, window.innerWidth/window.innerHeight, 1, 1000)
                camera.position.set(0, 3, 10);

                scene = new THREE.Scene();
                const gridHelper = new THREE.GridHelper(200, 100);
                scene.add(gridHelper);

				video = document.getElementById( 'video' );

                const videoTexture = new THREE.VideoTexture( video );

				const videoGeometry = new THREE.PlaneBufferGeometry( 16, 9 );
				videoGeometry.scale( 0.5, 0.5, 0.5 );
				const videoMaterial = new THREE.MeshBasicMaterial( { map: videoTexture } );
                
                const videoMesh = new THREE.Mesh( videoGeometry, videoMaterial );
                videoMesh.position.set( 0, 3, -5 );
                videoMesh.receiveShadow = true;
        
				scene.add( videoMesh );
                camera.lookAt(videoMesh);
				renderer = new THREE.WebGLRenderer( { antialias: true } );
				renderer.setPixelRatio( window.devicePixelRatio );
				renderer.setSize( window.innerWidth, window.innerHeight );
                renderer.shadowMap.enabled = true;
                renderer.shadowMap.type = THREE.PCFSoftShadowMap; // default THREE.PCFShadowMap
				document.body.appendChild( renderer.domElement );

				const controls = new OrbitControls( camera, renderer.domElement );
				controls.enableZoom = true;
				controls.enablePan = true;

                window.addEventListener( 'resize', onWindowResize, false );
                video.addEventListener('loadeddata', () => {
                    videoDataLoaded = true;
                }, false)
                
                //lights

				scene.add( new THREE.AmbientLight( 0xffffff, 0.3 ) );

                const spotLight = new THREE.SpotLight( 0xffffff, 0.5 );
                spotLight.angle = Math.PI / 5;
                spotLight.penumbra = 0.2;
                spotLight.distance = 200;
                spotLight.position.set( 2, 5, 5 );
                spotLight.castShadow = true;
                spotLight.shadow.mapSize.width = 512;
                spotLight.shadow.mapSize.height = 512;
                spotLight.shadow.camera.near = 0.5;
                spotLight.shadow.camera.far = 500;
                spotLight.shadow.focus = 1;
                spotLight.shadow.autoUpdate = true;
                scene.add( spotLight );

                var spotLightHelper = new THREE.SpotLightHelper( spotLight ); 
                //scene.add( spotLightHelper );

                const dirLight = new THREE.DirectionalLight( 0xffffff, 0.5 );
                dirLight.position.set( 0, 2, 0 );
                dirLight.castShadow = true;
                dirLight.shadow.camera.near = 1;
                dirLight.shadow.camera.far = 10;

                dirLight.shadow.camera.right = 1;
                dirLight.shadow.camera.left = - 1;
                dirLight.shadow.camera.top	= 1;
                dirLight.shadow.camera.bottom = - 1;

                dirLight.shadow.mapSize.width = 1024;
                dirLight.shadow.mapSize.height = 1024;
                scene.add( dirLight );

                const planeGeometry = new THREE.PlaneBufferGeometry( 3, 3, 1, 1 ),
                planeColor = new THREE.Color();

                const ground = new THREE.Mesh( planeGeometry,
					new THREE.MeshPhongMaterial( {
                        color: 0xa0adaf, shininess: 10 
                    } ) );
				ground.rotation.x = - Math.PI / 2;
				ground.scale.multiplyScalar( 3 );
				ground.receiveShadow = true;
				scene.add( ground );
                
                //

				if ( navigator.mediaDevices && navigator.mediaDevices.getUserMedia ) {

					const constraints = { video: { width: 1280, height: 720, facingMode: 'user' } };

					navigator.mediaDevices.getUserMedia( constraints ).then( function ( stream ) {

						// apply the stream to the video element used in the texture

						video.srcObject = stream;
                        video.play();
                        console.log("video initialized");
                        // videoDataLoaded = true;

					} ).catch( function ( error ) {

						console.error( 'Unable to access the camera/webcam.', error );

					} );

				} else {

					console.error( 'MediaDevices interface not available.' );

                }
                
                //

                for (var i = 0; i < 21; i++){ // 21 keypoints
                    var {isPalm,next} = getLandmarkProperty(i);

                    var obj = new THREE.Object3D(); // a parent object to facilitate rotation/scaling
                    obj.castShadow = true;

                    // we make each bone a cylindrical shape, but you can use your own models here too
                    var boneGeometry = new THREE.CylinderGeometry( isPalm?0.5:1.0, 0.5, 0.1);

                    var boneMaterial = new THREE.MeshNormalMaterial();
                    // another possible material (after adding a light source):
                    // var material = new THREE.MeshPhongMaterial({color:0x00ffff});

                    var boneMesh = new THREE.Mesh( boneGeometry, boneMaterial );
                    boneMesh.castShadow = true;
                    boneMesh.scale.set(0.1, 0.1, 0.1)
                    boneMesh.rotation.x = Math.PI/2;

                    obj.add( boneMesh );
                    scene.add(obj);
                    handMeshes.push(obj);
                }

                // Load the MediaPipe handpose model assets.
                handpose.load().then(function(_model){
                    console.log("model initialized.")
                    statusText = "Model loaded."
                    handposeModel = _model;                    
                })
            }

            // update threejs object position and orientation from the detected hand pose
            // threejs has a "scene" model, so we don't have to specify what to draw each frame,
            // instead we put objects at right positions and threejs renders them all
            function updateMeshes(hand){
                for (var i = 0; i < handMeshes.length; i++){

                    var {isPalm,next} = getLandmarkProperty(i);

                    var p0 = webcam2space(...hand.landmarks[i   ]);  // one end of the bone
                    var p1 = webcam2space(...hand.landmarks[next]);  // the other end of the bone

                    // compute the center of the bone (midpoint)
                    var mid = p0.clone().lerp(p1,0.5);
                    handMeshes[i].position.set(mid.x,mid.y,mid.z);

                    // compute the length of the bone
                    handMeshes[i].scale.z = p0.distanceTo(p1) * 100;

                    // compute orientation of the bone
                    handMeshes[i].lookAt(p1);
                    handMeshes[i].castShadow = true;

                }
            }

            // compute some metadata given a landmark index
            // - is the landmark a palm keypoint or a finger keypoint?
            // - what's the next landmark to connect to if we're drawing a bone?
            function getLandmarkProperty(i){
                var palms = [0,1,2,5,9,13,17] //landmark indices that represent the palm

                var idx = palms.indexOf(i);
                var isPalm = idx != -1;
                var next; // who to connect with?
                if (!isPalm){ // connect with previous finger landmark if it's a finger landmark
                    next = i-1;
                }else{ // connect with next palm landmark if it's a palm landmark
                    next = palms[(idx+1)%palms.length];
                }
                return {isPalm,next};
            }

                // draw a hand object (2D debug view) returned by handpose
            function drawHands(hands,noKeypoints){
            
                // Each hand object contains a `landmarks` property,
                // which is an array of 21 3-D landmarks.
                for (var i = 0; i < hands.length; i++){

                    var landmarks = hands[i].landmarks;

                    var palms = [0,1,2,5,9,13,17] //landmark indices that represent the palm

                    for (var j = 0; j < landmarks.length; j++){
                    var [x,y,z] = landmarks[j]; // coordinate in 3D space

                    // draw the keypoint and number
                    if (!noKeypoints){
                        dbg.fillRect(x-2,y-2,4,4);
                        dbg.fillText(j,x,y);
                    }
                        
                    // draw the skeleton
                    var {isPalm,next} = getLandmarkProperty(j);
                    dbg.beginPath();
                    dbg.moveTo(x,y);
                    dbg.lineTo(...landmarks[next]);
                    dbg.stroke();
                    }

                }
            }

            // transform webcam coordinates to threejs 3d coordinates
            function webcam2space(x,y,z){
                var newX = (x/100) - 7
                var newY = (y/100) - 7
                return new THREE.Vector3(
                    (newX),
                    -(newY), // in threejs, +y is up
                    - z/100
                )
            }

			function onWindowResize() {

				camera.aspect = window.innerWidth / window.innerHeight;
				camera.updateProjectionMatrix();

				renderer.setSize( window.innerWidth, window.innerHeight );

			}

			function animate() {

                requestAnimationFrame( animate );
                
                if (handposeModel && videoDataLoaded){ // model and video both loaded

                    handposeModel.estimateHands(video).then(function(_hands){
                    // we're handling an async promise
                    // best to avoid drawing something here! it might produce weird results due to racing
                    
                    myHands = _hands; // update the global myHands object with the detected hands
                    if (!myHands.length){
                        // haven't found any hands
                        statusText = "Show some hands!"
                    }else{
                        // display the confidence, to 3 decimal places
                        statusText = "Confidence: "+ (Math.round(myHands[0].handInViewConfidence*1000)/1000);
                        
                        // update 3d objects
                        updateMeshes(myHands[0]);
                    }
                    })
                }

                // dbg.clearRect(0,0,dbg.canvas.width,dbg.canvas.height);
  
                // dbg.save();
                // dbg.fillStyle="blue";
                // dbg.strokeStyle="blue";
                // dbg.scale(0.5,0.5); //halfsize;
                
                // //dbg.drawImage(video,0,0);
                // //drawHands(myHands);
                // dbg.restore();
                
                // dbg.save();
                // dbg.fillStyle="red";
                // dbg.fillText(statusText,2,60);
                // dbg.restore();

                renderer.render( scene, camera );

			}

		</script>

	</body>
</html>